{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634cbc9b",
   "metadata": {},
   "source": [
    "### Live video Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6934f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label(pred_idx):\n",
    "    labels = ['LeftSwipe', 'RightSwipe', 'Stop', 'ThumbsDown', 'ThumbsUp'] # Customize based on labels\n",
    "    return labels[pred_idx]\n",
    "\n",
    "def loadModel():# load the existing model\n",
    "    model = load_model(modelToLoad)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def cropResize(image, y, z):\n",
    "    h, w = image.shape\n",
    "\n",
    "    # if smaller image crop at center for 120x120\n",
    "    if w == 160:\n",
    "        image = image[:120, 20:140]\n",
    "\n",
    "    # resize every image\n",
    "    return resize(image, (y,z))\n",
    "\n",
    "def normalizeImage(image):\n",
    "    # applying normalization\n",
    "    return image/255.0  \n",
    "\n",
    "def preprocessImage(image, y, z):\n",
    "    return normalizeImage(cropResize(image, y, z))\n",
    "\n",
    "\n",
    "def main():\n",
    "    #print(\"Start*******\")\n",
    "    # load the model\n",
    "    model = loadModel()\n",
    "\n",
    "    #print(\"Model Load Done*******\")\n",
    "    #model.summary()\n",
    "\n",
    "    #infer = model.signatures[\"serving_default\"]\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)  # '0' is typically the default value for the webcam\n",
    " \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        exit()\n",
    "    \n",
    "    # Buffer to hold frames\n",
    "    frame_buffer = []\n",
    "\n",
    "    #c = 0\n",
    "    # Read frames from the webcam\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame\n",
    "        frame_resized = cv2.resize(frame, input_size)\n",
    "        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        frame_processed = frame_rgb.astype(np.float32) / 255.0\n",
    "\n",
    "        #print(\"Shape of Processed Frame:::\", frame_processed.shape)\n",
    "        # Convert frame to float32\n",
    "        #frame_processed = frame_processed.astype(np.float32) / 255\n",
    "\n",
    "        # Add the frame to the buffer\n",
    "        frame_buffer.append(frame_processed)\n",
    "\n",
    "        # Maintain only the last 20 frames\n",
    "        if len(frame_buffer) > sequence_length:\n",
    "            frame_buffer.pop(0)\n",
    "\n",
    "        #rgb_frame = cv2.cvtColor(frame_processed, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if len(frame_buffer) == sequence_length:\n",
    "            input_sequence = np.array(frame_buffer)\n",
    "            input_tensor = tf.convert_to_tensor(input_sequence, dtype=tf.float32)\n",
    "            #input_tensor = tf.image.per_image_standardization(input_tensor)\n",
    "            input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "            #print(\"*************************\",input_tensor.shape)\n",
    "\n",
    "            # Perform inference\n",
    "            #predictions = infer(input_tensor)\n",
    "            predictions = model.predict(input_tensor)\n",
    "            #print(predictions)\n",
    "            #output = predictions[\"dense\"].numpy()\n",
    "            output = predictions\n",
    "\n",
    "            \n",
    "            #print(\"******** Predicitons and prediction label***********\")\n",
    "            #print(output)\n",
    "            label = np.argmax(output, axis=-1)\n",
    "            #print(\"Label Data::\", label)\n",
    "            labelText = get_class_label(label[0])\n",
    "            #print(\"Prediction Label:::\",labelText)\n",
    "\n",
    "            label_text = f\"Prediction: {labelText}\"\n",
    "            cv2.putText(frame, label_text, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "\n",
    "\n",
    " \n",
    "        # Display the resulting frame\n",
    "        #cv2.imshow('Video', cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR))\n",
    "        cv2.imshow('Video', frame)\n",
    "        \n",
    " \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    input_size = (128, 128)\n",
    "    sequence_length = 30\n",
    "    modelToLoad = '/Users/jiten/Masters/Compute vision - CSC 528/CNN_Gesture_recognition/mobilenet_lstm_2024-06-0100_04_37.226216/model-keras.keras'\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
